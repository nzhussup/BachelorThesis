{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from time_counter import time_counter\n",
    "import keras_tuner as kt\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "def preproc(X,y) -> tuple:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=123)\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "    \n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "        \n",
    "    max_seq_length = max(len(x) for x in X_train_seq)\n",
    "    X_train_padded = pad_sequences(X_train_seq, maxlen=max_seq_length)\n",
    "    X_test_padded = pad_sequences(X_test_seq, maxlen=max_seq_length)\n",
    "    \n",
    "    if y_train.nunique() != 2:\n",
    "        y_train_cat = to_categorical(y_train, num_classes=y_train.nunique())\n",
    "        y_test_cat = to_categorical(y_test, num_classes=y_test.nunique())\n",
    "        return X_train_padded, X_test_padded, y_train_cat, y_test_cat, max_seq_length\n",
    "    \n",
    "    return X_train_padded, X_test_padded, np.array(y_train), np.array(y_test), max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_data = pd.read_csv(\"../data/clean_bbc_classification.csv\")\n",
    "sarc_data = pd.read_csv(\"../data/clean_sarcasm_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning params\n",
    "\n",
    "num_iterations = 5\n",
    "num_cv = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM on BBC News Classification\n",
    "#### Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bbc_data['text']\n",
    "y = bbc_data['label_ids']\n",
    "\n",
    "X_train, X_test, y_train, y_test, maxlen = preproc(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cpus = multiprocessing.cpu_count()\n",
    "num_cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 1835, 128)         640000    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 690533 (2.63 MB)\n",
      "Trainable params: 690533 (2.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen),\n",
    "    LSTM(64),\n",
    "    Dropout(0.5), \n",
    "    Dense(16, activation='relu'),  \n",
    "    Dense(bbc_data['label_ids'].nunique(), activation='softmax') \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 47s 779ms/step - loss: 1.5093 - accuracy: 0.3360 - val_loss: 1.1886 - val_accuracy: 0.4854\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 39s 705ms/step - loss: 0.9666 - accuracy: 0.5315 - val_loss: 0.8359 - val_accuracy: 0.6090\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 39s 696ms/step - loss: 0.6684 - accuracy: 0.6770 - val_loss: 0.6473 - val_accuracy: 0.7798\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 39s 698ms/step - loss: 0.4286 - accuracy: 0.8657 - val_loss: 0.4995 - val_accuracy: 0.8652\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 40s 707ms/step - loss: 0.2295 - accuracy: 0.9500 - val_loss: 0.3072 - val_accuracy: 0.9303\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 40s 716ms/step - loss: 0.0926 - accuracy: 0.9837 - val_loss: 0.3316 - val_accuracy: 0.9101\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 39s 693ms/step - loss: 0.0456 - accuracy: 0.9949 - val_loss: 0.2128 - val_accuracy: 0.9573\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 39s 704ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9551\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 39s 694ms/step - loss: 0.0338 - accuracy: 0.9910 - val_loss: 0.2717 - val_accuracy: 0.9056\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 39s 694ms/step - loss: 0.0243 - accuracy: 0.9955 - val_loss: 0.2325 - val_accuracy: 0.9483\n",
      "14/14 [==============================] - 3s 186ms/step\n",
      "LSTM (BBC data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        65\n",
      "           1       0.95      0.99      0.97       103\n",
      "           2       1.00      1.00      1.00       114\n",
      "           3       0.89      0.97      0.93        88\n",
      "           4       0.97      0.88      0.92        75\n",
      "\n",
      "    accuracy                           0.96       445\n",
      "   macro avg       0.96      0.95      0.95       445\n",
      "weighted avg       0.96      0.96      0.96       445\n",
      "\n",
      "Runtime: 402.97 seconds\n"
     ]
    }
   ],
   "source": [
    "@time_counter\n",
    "def model_fit():\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100, validation_data=[X_test, y_test], callbacks=[early_stop])\n",
    "    preds = model.predict(X_test)\n",
    "    print(\"LSTM (BBC data)\")\n",
    "    print(classification_report(np.argmax(y_test,axis=1),np.argmax(preds, axis=1)))\n",
    "    return preds\n",
    "\n",
    "preds, runtime_lstm = model_fit()\n",
    "print(f\"Runtime: {runtime_lstm} seconds\")\n",
    "performance_lstm = classification_report(np.argmax(y_test,axis=1), np.argmax(preds, axis=1), output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuned LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, \n",
    "                        output_dim=hp.Int('embedding_dim', min_value=64, max_value=256, step=32), \n",
    "                        input_length=maxlen))\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=256, step=32)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('dense_units', min_value=16, max_value=128, step=16), activation='relu'))\n",
    "    model.add(Dense(bbc_data['label_ids'].nunique(), activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.RandomSearch(build_model, \n",
    "                        objective='val_accuracy', \n",
    "                        max_trials=num_iterations, \n",
    "                        executions_per_trial=num_cv, \n",
    "                        directory='lstm', \n",
    "                        project_name='lstm_tuning_bbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 40m 17s]\n",
      "val_accuracy: 0.9318352142969767\n",
      "\n",
      "Best val_accuracy So Far: 0.9415730436642965\n",
      "Total elapsed time: 05h 35m 45s\n",
      "14/14 [==============================] - 2s 105ms/step\n",
      "Fine-tuned LSTM (BBC data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95        65\n",
      "           1       0.94      0.98      0.96       103\n",
      "           2       0.98      0.99      0.99       114\n",
      "           3       0.95      0.93      0.94        88\n",
      "           4       0.93      0.91      0.92        75\n",
      "\n",
      "    accuracy                           0.96       445\n",
      "   macro avg       0.95      0.95      0.95       445\n",
      "weighted avg       0.95      0.96      0.95       445\n",
      "\n",
      "Runtime: 20148.4 seconds\n"
     ]
    }
   ],
   "source": [
    "@time_counter\n",
    "def model_tuning():\n",
    "    tuner.search(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    preds = best_model.predict(X_test)\n",
    "    print(\"Fine-tuned LSTM (BBC data)\")\n",
    "    print(classification_report(np.argmax(y_test, axis=1), np.argmax(preds, axis=1)))\n",
    "    return preds\n",
    "\n",
    "preds, runtime_lstm_tuned = model_tuning()\n",
    "print(f\"Runtime: {runtime_lstm_tuned} seconds\")\n",
    "performance_lstm_tuned = classification_report(np.argmax(y_test, axis=1), np.argmax(preds, axis=1), output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.849438</td>\n",
       "      <td>0.849514</td>\n",
       "      <td>bbc news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree fine-tuned</td>\n",
       "      <td>8.08</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.632672</td>\n",
       "      <td>bbc news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.730084</td>\n",
       "      <td>0.729078</td>\n",
       "      <td>sarcasm detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree fine-tuned</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0.615828</td>\n",
       "      <td>0.567973</td>\n",
       "      <td>sarcasm detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.970787</td>\n",
       "      <td>0.970774</td>\n",
       "      <td>bbc news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest fine-tuned</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.959551</td>\n",
       "      <td>0.959489</td>\n",
       "      <td>bbc news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>10.27</td>\n",
       "      <td>0.767121</td>\n",
       "      <td>0.764883</td>\n",
       "      <td>sarcasm detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest fine-tuned</td>\n",
       "      <td>82.99</td>\n",
       "      <td>0.771139</td>\n",
       "      <td>0.770207</td>\n",
       "      <td>sarcasm detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>402.97</td>\n",
       "      <td>0.957303</td>\n",
       "      <td>0.957100</td>\n",
       "      <td>bbc news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LSTM fine-tuned</td>\n",
       "      <td>20148.40</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.954870</td>\n",
       "      <td>bbc news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   Runtime  Accuracy        F1               data\n",
       "0             Decision Tree      0.73  0.849438  0.849514           bbc news\n",
       "1  Decision Tree fine-tuned      8.08  0.617978  0.632672           bbc news\n",
       "2             Decision Tree     14.38  0.730084  0.729078  sarcasm detection\n",
       "3  Decision Tree fine-tuned      8.67  0.615828  0.567973  sarcasm detection\n",
       "4             Random Forest      0.42  0.970787  0.970774           bbc news\n",
       "5  Random Forest fine-tuned      8.90  0.959551  0.959489           bbc news\n",
       "6             Random Forest     10.27  0.767121  0.764883  sarcasm detection\n",
       "7  Random Forest fine-tuned     82.99  0.771139  0.770207  sarcasm detection\n",
       "8                      LSTM    402.97  0.957303  0.957100           bbc news\n",
       "9           LSTM fine-tuned  20148.40  0.955056  0.954870           bbc news"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/evaluation_data_2.csv\")\n",
    "data = pd.concat([data,\n",
    "                  pd.DataFrame({\n",
    "                      'Model': ['LSTM', 'LSTM fine-tuned'],\n",
    "                      'Runtime': [runtime_lstm, runtime_lstm_tuned],\n",
    "                      'Accuracy': [performance_lstm['accuracy'], performance_lstm_tuned['accuracy']],\n",
    "                      'F1': [performance_lstm['weighted avg']['f1-score'], performance_lstm_tuned['weighted avg']['f1-score']],\n",
    "                      'data': ['bbc news', 'bbc news']\n",
    "                  })], ignore_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ON SARC DATA\n",
    "#### Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarc_data = sarc_data.dropna()\n",
    "X = sarc_data['text']\n",
    "y = sarc_data['is_sarcastic']\n",
    "\n",
    "X_train, X_test, y_train, y_test, maxlen = preproc(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 73, 128)           640000    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 690465 (2.63 MB)\n",
      "Trainable params: 690465 (2.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen),\n",
    "    LSTM(64),\n",
    "    Dropout(0.5), \n",
    "    Dense(16, activation='relu'),  \n",
    "    Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "716/716 [==============================] - 29s 38ms/step - loss: 0.5172 - accuracy: 0.7339 - val_loss: 0.4452 - val_accuracy: 0.7870\n",
      "Epoch 2/100\n",
      "716/716 [==============================] - 26s 37ms/step - loss: 0.3625 - accuracy: 0.8371 - val_loss: 0.4392 - val_accuracy: 0.7909\n",
      "Epoch 3/100\n",
      "716/716 [==============================] - 26s 37ms/step - loss: 0.2814 - accuracy: 0.8738 - val_loss: 0.4942 - val_accuracy: 0.7828\n",
      "Epoch 4/100\n",
      "716/716 [==============================] - 27s 37ms/step - loss: 0.2226 - accuracy: 0.8970 - val_loss: 0.6311 - val_accuracy: 0.7757\n",
      "Epoch 5/100\n",
      "716/716 [==============================] - 27s 37ms/step - loss: 0.1807 - accuracy: 0.9159 - val_loss: 0.7344 - val_accuracy: 0.7715\n",
      "179/179 [==============================] - 2s 11ms/step\n",
      "LSTM (Sarcasm Detection)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80      2978\n",
      "           1       0.78      0.79      0.78      2746\n",
      "\n",
      "    accuracy                           0.79      5724\n",
      "   macro avg       0.79      0.79      0.79      5724\n",
      "weighted avg       0.79      0.79      0.79      5724\n",
      "\n",
      "Runtime: 138.59 seconds\n"
     ]
    }
   ],
   "source": [
    "@time_counter\n",
    "def model_fit():\n",
    "    model.fit(X_train, y_train, epochs=100, validation_data=[X_test, y_test], callbacks=[early_stop])\n",
    "    preds = (model.predict(X_test) >= 0.5).astype(int)\n",
    "    print(\"LSTM (Sarcasm Detection)\")\n",
    "    print(classification_report(y_test,preds))\n",
    "    return preds\n",
    "\n",
    "preds, runtime_lstm = model_fit()\n",
    "print(f\"Runtime: {runtime_lstm} seconds\")\n",
    "performance_lstm = classification_report(y_test,preds, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuned LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, \n",
    "                        output_dim=hp.Int('embedding_dim', min_value=64, max_value=256, step=32), \n",
    "                        input_length=maxlen))\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=256, step=32)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('dense_units', min_value=16, max_value=128, step=16), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.RandomSearch(build_model, \n",
    "                        objective='val_accuracy', \n",
    "                        max_trials=num_iterations, \n",
    "                        executions_per_trial=num_cv, \n",
    "                        directory='lstm_sarc', \n",
    "                        project_name='lstm_tuning_sarc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 21m 00s]\n",
      "val_accuracy: 0.520265519618988\n",
      "\n",
      "Best val_accuracy So Far: 0.520265519618988\n",
      "Total elapsed time: 00h 55m 50s\n",
      "179/179 [==============================] - 5s 24ms/step\n",
      "Fine-tuned LSTM (Sarcasm detection data)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68      2978\n",
      "           1       0.00      0.00      0.00      2746\n",
      "\n",
      "    accuracy                           0.52      5724\n",
      "   macro avg       0.26      0.50      0.34      5724\n",
      "weighted avg       0.27      0.52      0.36      5724\n",
      "\n",
      "Runtime: 3356.2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibragimzhussup/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ibragimzhussup/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ibragimzhussup/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ibragimzhussup/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ibragimzhussup/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ibragimzhussup/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "@time_counter\n",
    "def model_tuning():\n",
    "    tuner.search(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    preds = (best_model.predict(X_test) >= 0.5).astype(int)\n",
    "    print(\"Fine-tuned LSTM (Sarcasm detection data)\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    return preds\n",
    "\n",
    "preds, runtime_lstm_tuned = model_tuning()\n",
    "print(f\"Runtime: {runtime_lstm_tuned} seconds\")\n",
    "performance_lstm_tuned = classification_report(y_test, preds, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.849438</td>\n",
       "      <td>0.849514</td>\n",
       "      <td>bbc news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree fine-tuned</td>\n",
       "      <td>8.08</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.632672</td>\n",
       "      <td>bbc news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.730084</td>\n",
       "      <td>0.729078</td>\n",
       "      <td>sarcasm detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree fine-tuned</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0.615828</td>\n",
       "      <td>0.567973</td>\n",
       "      <td>sarcasm detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.970787</td>\n",
       "      <td>0.970774</td>\n",
       "      <td>bbc news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest fine-tuned</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.959551</td>\n",
       "      <td>0.959489</td>\n",
       "      <td>bbc news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>10.27</td>\n",
       "      <td>0.767121</td>\n",
       "      <td>0.764883</td>\n",
       "      <td>sarcasm detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest fine-tuned</td>\n",
       "      <td>82.99</td>\n",
       "      <td>0.771139</td>\n",
       "      <td>0.770207</td>\n",
       "      <td>sarcasm detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>402.97</td>\n",
       "      <td>0.957303</td>\n",
       "      <td>0.957100</td>\n",
       "      <td>bbc news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LSTM fine-tuned</td>\n",
       "      <td>20148.40</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.954870</td>\n",
       "      <td>bbc news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>138.59</td>\n",
       "      <td>0.790881</td>\n",
       "      <td>0.790951</td>\n",
       "      <td>sarcasm detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSTM fine-tuned</td>\n",
       "      <td>3356.20</td>\n",
       "      <td>0.520266</td>\n",
       "      <td>0.356091</td>\n",
       "      <td>sarcasm detection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model   Runtime  Accuracy        F1               data\n",
       "0              Decision Tree      0.73  0.849438  0.849514           bbc news\n",
       "1   Decision Tree fine-tuned      8.08  0.617978  0.632672           bbc news\n",
       "2              Decision Tree     14.38  0.730084  0.729078  sarcasm detection\n",
       "3   Decision Tree fine-tuned      8.67  0.615828  0.567973  sarcasm detection\n",
       "4              Random Forest      0.42  0.970787  0.970774           bbc news\n",
       "5   Random Forest fine-tuned      8.90  0.959551  0.959489           bbc news\n",
       "6              Random Forest     10.27  0.767121  0.764883  sarcasm detection\n",
       "7   Random Forest fine-tuned     82.99  0.771139  0.770207  sarcasm detection\n",
       "8                       LSTM    402.97  0.957303  0.957100           bbc news\n",
       "9            LSTM fine-tuned  20148.40  0.955056  0.954870           bbc news\n",
       "10                      LSTM    138.59  0.790881  0.790951  sarcasm detection\n",
       "11           LSTM fine-tuned   3356.20  0.520266  0.356091  sarcasm detection"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data,\n",
    "                  pd.DataFrame({\n",
    "                      'Model': ['LSTM', 'LSTM fine-tuned'],\n",
    "                      'Runtime': [runtime_lstm, runtime_lstm_tuned],\n",
    "                      'Accuracy': [performance_lstm['accuracy'], performance_lstm_tuned['accuracy']],\n",
    "                      'F1': [performance_lstm['weighted avg']['f1-score'], performance_lstm_tuned['weighted avg']['f1-score']],\n",
    "                      'data': ['sarcasm detection', 'sarcasm detection']\n",
    "                  })], ignore_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../data/evaluation_data_final.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
